apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "semantic-router.fullname" . }}
  namespace: {{ include "semantic-router.namespace" . }}
  labels:
    {{- include "semantic-router.labels" . | nindent 4 }}
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      {{- include "semantic-router.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "semantic-router.selectorLabels" . | nindent 8 }}
    spec:
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- if .Values.models.download.enabled }}
      initContainers:
      - name: model-downloader
        image: python:3.11-slim
        securityContext:
          runAsNonRoot: false
          allowPrivilegeEscalation: false
        command: ["/bin/bash", "-c"]
        args:
          - |
            set -e
            # Check if all required models already exist in PVC; if yes, skip downloads entirely
            REQUIRED_DIRS=(
              "all-MiniLM-L12-v2"
              "category_classifier_modernbert-base_model"
            )
            mkdir -p /app/models
            cd /app/models
            MISSING=false
            for d in "${REQUIRED_DIRS[@]}"; do
              if [ ! -d "$d" ]; then
                MISSING=true
                break
              fi
            done
            if [ "$MISSING" = false ]; then
              echo "All required models already present in PVC. Skipping download."
              exit 0
            fi

            echo "Installing Hugging Face CLI..."
            pip install --no-cache-dir huggingface_hub[cli]

            echo "Downloading missing models to persistent volume..."

            # Download all-MiniLM-L12-v2 model
            if [ ! -d "all-MiniLM-L12-v2" ]; then
              echo "Downloading all-MiniLM-L12-v2 model..."
              hf download sentence-transformers/all-MiniLM-L12-v2 --local-dir all-MiniLM-L12-v2
            else
              echo "all-MiniLM-L12-v2 model already exists, skipping..."
            fi

            # Download category classifier model
            if [ ! -d "category_classifier_modernbert-base_model" ]; then
              echo "Downloading category classifier model..."
              hf download LLM-Semantic-Router/category_classifier_modernbert-base_model --local-dir category_classifier_modernbert-base_model
            else
              echo "Category classifier model already exists, skipping..."
            fi

            echo "All missing models downloaded successfully!"
            ls -la /app/models/
        env:
        - name: HF_HUB_CACHE
          value: /tmp/hf_cache
        resources:
          {{- toYaml .Values.resources.initContainer | nindent 10 }}
        volumeMounts:
        - name: models-volume
          mountPath: /app/models
      {{- end }}
      containers:
      - name: {{ .Chart.Name }}
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        args: ["--secure=false"]
        securityContext:
          {{- toYaml .Values.securityContext | nindent 10 }}
        ports:
        - containerPort: {{ .Values.service.grpc.port }}
          name: {{ .Values.service.grpc.name }}
          protocol: TCP
        - containerPort: {{ .Values.service.api.port }}
          name: {{ .Values.service.api.name }}
          protocol: TCP
        {{- if .Values.service.metrics.enabled }}
        - containerPort: {{ .Values.service.metrics.port }}
          name: {{ .Values.service.metrics.name }}
          protocol: TCP
        {{- end }}
        env:
        - name: LD_LIBRARY_PATH
          value: "/app/lib"
        volumeMounts:
        - name: config-volume
          mountPath: /app/config
          readOnly: true
        {{- if .Values.persistence.enabled }}
        - name: models-volume
          mountPath: /app/models
        {{- end }}
        {{- if .Values.livenessProbe.enabled }}
        livenessProbe:
          tcpSocket:
            port: {{ .Values.service.grpc.name }}
          initialDelaySeconds: {{ .Values.livenessProbe.initialDelaySeconds }}
          periodSeconds: {{ .Values.livenessProbe.periodSeconds }}
          timeoutSeconds: {{ .Values.livenessProbe.timeoutSeconds }}
          failureThreshold: {{ .Values.livenessProbe.failureThreshold }}
        {{- end }}
        {{- if .Values.readinessProbe.enabled }}
        readinessProbe:
          tcpSocket:
            port: {{ .Values.service.grpc.name }}
          initialDelaySeconds: {{ .Values.readinessProbe.initialDelaySeconds }}
          periodSeconds: {{ .Values.readinessProbe.periodSeconds }}
          timeoutSeconds: {{ .Values.readinessProbe.timeoutSeconds }}
          failureThreshold: {{ .Values.readinessProbe.failureThreshold }}
        {{- end }}
        resources:
          {{- toYaml .Values.resources.mainContainer | nindent 10 }}
      volumes:
      - name: config-volume
        configMap:
          name: {{ include "semantic-router.fullname" . }}-config
      {{- if .Values.persistence.enabled }}
      - name: models-volume
        persistentVolumeClaim:
          claimName: {{ include "semantic-router.fullname" . }}-models
      {{- end }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
